{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題とは？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 何かをグループに分ける処理　主に「教師あり学習」の場合を指す\n",
    "* 一方で、何か大小に意味のある数値を予測する処理を、回帰問題と呼ぶ\n",
    "* ベクトル空間モデルを利用した場合、文書などのアイテムは多次元空間の点として表すことができる　素性数が2なら二次元空間上の点\n",
    "* 決定関数を用いて分類する境界線を表す\n",
    "* 汎用性の高い学習データを用いて学習を行う必要がある。\n",
    "* 開発データを用いて、未学習と過学習のバランスをとる\n",
    "* sklearn.model_selection.train_test_splitモジュールで、データを分割することができる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 分類アルゴリズムで最も単純な方法\n",
    "* ベイズの定理：$ P(X)P(Y|X)=P(Y)P(X|Y) $\n",
    "* $ P(C|d)=P(C|w_1,w_2,...,w_n), 文書d, i番目の単語:w_i, 分類先のクラス $\n",
    "* $ ある文書d=w_1,...,w_nがクラスCに属する確率 $\n",
    "* $ P(d)P(C|d)=P(C)P(d|C)より、P(C|d)=\\frac{P(C)P(d|C)}{P(d)} $ ...\n",
    "* $ P(C|d) $：文書内のカテゴリー出現率、$ P(C) $：カテゴリー出現率、$ P(d|C) $：カテゴリー内の文書出現率\n",
    "* スムージング：ゼロ頻度問題を緩和する手法\n",
    "    * ゼロ頻度問題：学習データ内に出現しなかった単語は新規データで扱うことができないという問題のこと\n",
    "* $ P(w_i|C)=\\frac{C(w_i|C)+\\alpha}{N_C+\\alpha V} $\n",
    "* $ C(w_i|C) $：単語$ w_i $のクラスCの文書中の出現頻度、$ N_C $：クラスCの文書の全単語数、$ V $：語彙数\n",
    "* 全ての単語が実際よりごく少ない回数($ \\alpha $回)出てきたと考えて、全ての単語に$ \\alpha $を追加した式\n",
    "* 参照：https://qiita.com/ishizakiiii/items/07cc7e463dceb3efe1a1\n",
    "* とにかく、学習データを新規データに使えるように形にしたい！\n",
    "\n",
    "* 単純グッド・チューリング法：$ r^* = (r+1)\\frac{N_{r+1}}{N{r}} $  ($ N_r $：コーパス内でr回出てきた単語の数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_dict(file):   #学習データを読み込み、素性のインデックス辞書featsとラベルのインデックス辞書labelsを作成する関数\n",
    "  feats, labels = {}, {}\n",
    "  findex, lindex= 0, 0\n",
    "  with open(file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "      list=line.split(' ')  # 分かち書きリスト\n",
    "      for item in list:\n",
    "        word, right = item.split(\":\")\n",
    "        #素性の処理\n",
    "        if (word not in feats) and (word != \"#label#\"):\n",
    "          feats[word]=findex\n",
    "          findex+=1\n",
    "        elif word == \"#label#\": #ラベルの処理\n",
    "          right=right.replace('\\n', '') \n",
    "          if right not in labels:\n",
    "            labels[right]=lindex\n",
    "            lindex+=1\n",
    "    return feats, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = Make_dict('train.processed')  #Amazonレビューデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)  #値はインデックス番号の辞書となっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19983"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)  #素性数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 0, 'negative': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels  #肯定・否定の２クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_sample_vectors(file, feats, label_dict):   #ファイルと、素性辞書とラベル辞書を引数にとり、用例ベクトルのリストとそれに対応する答えのリストを返す関数\n",
    "  samples, label_list =[], []\n",
    "  with open(file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "      list=line.split(' ')\n",
    "      asample = [0] * len(feats)\n",
    "      for item in list:\n",
    "        word, right = item.split(\":\")\n",
    "        if word == \"#label#\": #ラベルの処理\n",
    "          label_list.append(int(label_dict[right.replace('\\n', '')])) # positive or negative = 0 or 1\n",
    "        else:  #素性の処理\n",
    "          if word in feats:\n",
    "            asample[feats[word]]=int(right)\n",
    "      samples.append(asample)\n",
    "  return samples, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y = Make_sample_vectors('train.processed', features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_Y = Make_sample_vectors('test.processed', features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多クラス分類の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janome\n",
    "import re\n",
    "from janome.tokenizer import Tokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b') #日本語対応\n",
    "\n",
    "\n",
    "#ファイルを入れて分かち書きした文のリストと、それに対応するスコア（星の数）のリストを返す\n",
    "def Get_Tokenized_senntences_and_Ratings(file): \n",
    "\n",
    "  with open(file, encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    data = data.replace('\\n', '')\n",
    "    data = data.replace('\\r', '')\n",
    "\n",
    "  reviews = re.findall(pattern=r'<item>(.+?)</item>',string=data) #testにひとつだけratingはあるのにtextがない感想があったため\n",
    "  \n",
    "  tokenized_sentences, ratings = [],[]\n",
    "\n",
    "  for index in range(len(reviews)):\n",
    "    rating = re.findall(pattern=r'<rating>(.+?)</rating>',string=reviews[index])\n",
    "    text = re.findall(pattern=r'<text>(.+?)</text>',string=reviews[index])\n",
    "    if rating and text: #testにひとつだけtextがない感想があったため\n",
    "      words=[token for token in t.tokenize(text[0], wakati=True)]\n",
    "      ratings.append(int(float(rating[0]))-1)\n",
    "      a_tokenized_sentence=\" \".join(words)\n",
    "      tokenized_sentences.append(a_tokenized_sentence)\n",
    " \n",
    "  return tokenized_sentences, ratings\n",
    "\n",
    "#ファイルを入れて分かち書きした文のリストと、それに対応するスコア（星の数）のリストを返す\n",
    "def Make_sample_vectors_for_Multiclass(train_file, test_file):\n",
    "  tokenized_sentences_train, ytrain =Get_Tokenized_senntences_and_Ratings(train_file)\n",
    "  Xtrain = vectorizer.fit_transform(tokenized_sentences_train)\n",
    "  feature_names = vectorizer.get_feature_names_out(tokenized_sentences_train)\n",
    "\n",
    "  tokenized_sentences_test, ytest=Get_Tokenized_senntences_and_Ratings(test_file)\n",
    "  Xtest = vectorizer.transform(tokenized_sentences_test)\n",
    "\n",
    "  return Xtrain, ytrain, feature_names, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, feat_names, test_x, test_y = Make_sample_vectors_for_Multiclass('train.review', 'test.review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19983"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "cl = BernoulliNB()\n",
    "cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.score(test_X, test_Y)  #正解率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7565"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = BernoulliNB(alpha=0.5)  #加算スムージングのalphaを0.5に指定\n",
    "cl.fit(train_X, train_Y)\n",
    "cl.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB  #多クラス分類\n",
    "cl2 = MultinomialNB()\n",
    "cl2.fit(train_x, train_y)\n",
    "cl2.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文書分類の評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 正解率が主流　正解数÷問題数\n",
    "* スパムメールか否かを分類→「スパムメールをスパムメールを判断」と「スパムメールではないメールをスパムメールではないと判断」の２通りが正解数となる\n",
    "* 精度、再現率、F値から評価する方がよい\n",
    "* 精度：成り立つと予測したもののうち、実際に成り立つものの割合\n",
    "* 再現率：実際に成り立つもののうち、成り立つと予測したものの割合\n",
    "* 精度と再現率はトレードオフ→F値で評価\n",
    "* $ F値=\\frac{2×精度×再現率}{正解率+再現率} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = BernoulliNB(alpha=1)  #加算スムージングのalphaを1に指定\n",
    "cl.fit(train_X, train_Y)\n",
    "cl.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ans_list = cl.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83001328, 0.69927827])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score  #精度の計算\n",
    "precision_score(test_Y, test_ans_list, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans_list2 = test_ans_list.tolist()  #ndarray型からリスト型二変換\n",
    "test_ans_list2.count(0)  #肯定(0)に予測された数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans_list2.count(1)  #否定(1)に予測された数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_ans_list2[i]==0 and test_ans_list2[i] == test_Y[i] for i in range(len(test_ans_list2))].count(True)  #肯定の正解数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[test_ans_list2[i]==1 and test_ans_list2[i] == test_Y[i] for i in range(len(test_ans_list2))].count(True)  #否定の正解数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_Y, test_ans_list, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646457740276531"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_Y, test_ans_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.625, 0.872])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "recall_score(test_Y, test_ans_list, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_Y, test_ans_list, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7484999999999999"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_Y, test_ans_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71306332, 0.77614597])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_Y, test_ans_list, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7485"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_Y, test_ans_list, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446046462152363"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_Y, test_ans_list, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロジスティック回帰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ロジスティック関数：0から1の間の出力となる\n",
    "* 回帰の方法であるが、分類が可能である！\n",
    "* 「出力が0.5以上の時は1とする」などとすれば、分類問題となる\n",
    "* $ y=\\frac{1}{1+e^{-ax}} $、xの次数によって決定境界の関数を決定\n",
    "* $ x=\\sum_{i=1}^{n}w_ix_i+b $\n",
    "* $ w_i $を損失関数の最小化によって求める→尤度関数の最大化\n",
    "* 損失関数：予測値と実測値のずれの大きさを表したもの→ロジスティック関数ならクロスエントロピー\n",
    "* クロスエントロピー：2つの確率分布の間に定義される尺度\n",
    "* $ Loss(w)=-\\sum_{i=1}^{N}{(I_n\\log(y_{n,w})+(1-I_n)\\log(1-y_{n.w})}) $\n",
    "* N：学習データ数、$ I_n $：n番目の学習データのラベル、$ y_{n,w} $：n番目の学習データの入力素性に対して、$ w_i $で学習した場合の予測確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cl = LogisticRegression(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(train_X)  #単位の違いを調整するために標準化の変換器を作成\n",
    "train_X_scaled = scaler.transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.00378077,  2.11182876,  1.48907797, ..., -0.02236627,\n",
       "       -0.02236627, -0.02236627])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.78910723,  0.0687002 , -1.09694313, ..., -0.02236627,\n",
       "       -0.02236627, -0.02236627])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.fit(train_X_scaled, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.score(test_X_scaled, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ans_list = cl.predict(test_X_scaled)\n",
    "precision_score(test_Y, test_ans_list, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7446046462152363"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_Y, test_ans_list, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ 正則化：Loss(w)=-C\\sum_{i=1}^{N}{(I_n\\log(y_{n,w})+(1-I_n)\\log(1-y_{n.w})})+\\frac{1}{2}\\sum_{j=1}^{M}w_j^2 $\n",
    "* C：正則化の程度を指定するオプション\n",
    "* 重みパラメータの2乗を足し合わせることによって、重みパラメータの数を減らし、学習データに細かく合わせることができなくなるという点で、過学習を防ぐことができる。\n",
    "* 2乗を足し合わせる→L2正則化、絶対値を足し合わせる→L1正則化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not標準化\n",
    "cl2 = LogisticRegression(solver='liblinear')\n",
    "cl2.fit(train_X, train_Y)\n",
    "cl2.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.738"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 標準化\n",
    "cl2.fit(train_X_scaled, train_Y)\n",
    "cl2.score(test_X_scaled, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayesの多クラス分類\n",
    "* softmax関数：$ P(y_i|x)=\\frac{e^{x_i}}{\\sum_{k=1}^{K}e^{x_k}}$、K：クラスの数\n",
    "* $ P(y_i|x) $：$ x_i $を入力にとったときにi番目のクラス$ y_i $が起こる確率\n",
    "* $ e^x $は非負であるため、負の値から大きな値まで大小関係を保ったままの正の値に変換可能\n",
    "* さらに、softmax関数では、その正の値を足して1になるように正規化することで、その出力を確率として扱うことができる\n",
    "* $ K=2 $としたとき、ロジスティック関数と等価となる→ロジスティック関数を用いた多クラス分類への拡張がsoftmax関数の分類である\n",
    "* クロスエントロピー：2つの確率分布の間に定義される尺度\n",
    "* $ Loss(w)=-\\sum_{n=1}^{N}\\sum_{k=1}^{K}I_{n,k}\\log(y_{n,w,k}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4847423711855928"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多クラス分類\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cl_soft = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "cl_soft.fit(train_x, train_y)\n",
    "cl_soft.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# サポートベクターマシン(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 決定関数を学習で求めてから分類を行う→「超平面」\n",
    "* 3次元空間上の点の集合を2次元の超平面で分類する\n",
    "* 一般化すると、N次元空間上の点の集合はN-1次元の超平面で分類可能である\n",
    "* サポートベクター：決定境界から最も近くにある用例\n",
    "* サポートベクターと決定境界の距離マージンを最大化する決定関数を学習させる\n",
    "* $ 決定関数：y=\\sum_{i=1}^{n}w_ix_i+b $、$ x_i：一つの素性, w_i：重み, b：切片 $\n",
    "* $ y=\\bf{W}^T\\bf{X}+b $\n",
    "* 点(サポートベクター)と直線(決定関数)の距離：$ \\frac{|\\bf{W}^T\\bf{X}+b|}{\\sqrt{\\bf{W}^2}} $ を最大化\n",
    "* $ y=0 $(超平面H), $ y=1 $(超平面H1), $ y=-1 $(超平面H2)を考える\n",
    "* $ y_i=\\bf{W}^T X_j+b $ の値が1以上ならH1に、-1以下ならH2に分類する\n",
    "* ソフトマージンについては、テキストを参照\n",
    "* 二値分類を複数回実行して多クラス分類を行う→pairwise法とOne-vs-One法が存在\n",
    "* pairwise法：クラスの対ごとにどちらのクラスに属するかを決定する手法\n",
    "* A,B,Cの三つのクラスへの分類→A,B、B,C、C,Aの3回の二値分類を行う\n",
    "* One-vs-One法：クラスごとにそのクラスに属するかを決定する手法\n",
    "* A,B,Cの三つのクラスへの分類→Aか否か、Bか否か、Cか否かの3回の二値分類を行う\n",
    "* どちらも矛盾が生じる場合があるが、分類平面との距離が遠い(距離マージンが大きくなる)方のクラスに決定すればよい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "cl = SVC(gamma='auto')\n",
    "cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_linear = SVC(gamma='auto', kernel='linear')\n",
    "cl_linear.fit(train_X, train_Y)\n",
    "cl_linear.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45522761380690346"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多クラス分類\n",
    "from sklearn.svm import SVC\n",
    "cl_multi=SVC(gamma='auto', kernel='linear')\n",
    "cl_multi.fit(train_x, train_y)\n",
    "cl_multi.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45522761380690346"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_multi = SVC(gamma='auto', kernel='linear', decision_function_shape='ovo')  #One-vs-One法を用いる\n",
    "cl_multi.fit(train_x, train_y)\n",
    "cl_multi.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34317158579289647"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# polyカーネル\n",
    "cl_multi_poly = SVC(gamma='auto', kernel='poly')\n",
    "cl_multi_poly.fit(train_x, train_y)\n",
    "cl_multi_poly.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "cl = LinearSVC()\n",
    "cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_1000 = LinearSVC(C=1000)  #正則化パラメータを変更\n",
    "cl_1000.fit(train_X, train_Y)\n",
    "cl_1000.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46473236618309155"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "cl = LinearSVC()\n",
    "cl.fit(train_x, train_y)\n",
    "cl.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45672836418209106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = LinearSVC(C=1000)  #ハードマージンで分類\n",
    "cl.fit(train_x, train_y)\n",
    "cl.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $ y=f(\\sum_{i=1}^{n}x_iw_i+b), y：出力, x_i：i番目の入力, w_i：x_iの重み, -b：閾値 $\n",
    "* $ f $：活性化関数\n",
    "* $ ステップ関数：f(I)=1,I≧0 ; f(I)=0,I＜0 $→入力が0を超えると、ニューロンが発火する(1になる)\n",
    "* $ I=\\sum_{i=1}^{n}x_iw_i+b $とすると、上記の式が得られる\n",
    "* 一つのニューロンモデルからなるニューラルネットワーク→単純パーセプトロン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単純パーセプトロン\n",
    "* ロジスティック関数→ロジスティック回帰式、損失関数→クロスエントロピー式\n",
    "* softmax関数→多クラス分類のロジスティック回帰式、損失関数→多クラス分類のクロスエントロピー式\n",
    "* 複数組み合わせたもの→多層パーセプトロン\n",
    "* 多層パーセプトロンにおける入力層と出力層の間の層→中間層、隠れ層\n",
    "* 中間層を増やすと、決定関数が複雑になり、線形ではない分け方が可能となる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 誤差逆伝播法\n",
    "* 参照(ヨビノリ)：https://www.youtube.com/watch?v=0itH0iDO8BE\n",
    "* 革新的な重みの学習法\n",
    "* 行列に対する勾配降下法\n",
    "* 局所誤差の最小化\n",
    "\n",
    "##### 手順\n",
    "* ニューラルネットワークに学習サンプルを与える\n",
    "* NNの出力から出力層における誤差を求め、各出力ニューロンについて誤差を計算する\n",
    "* 個々のニューロンの期待される出力値と倍率、要求された出力と実際の出力との差(局所誤差)を計算する\n",
    "* 各ニューロンの重みを局所誤差が小さくなるよう調整する\n",
    "* より大きな重みで接続された前段のニューロンに対して、局所誤差の責任があると判定する\n",
    "* そのように判定された前段のニューロンのさらに前段のニューロン群について同様の処理を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "cl = MLPClassifier(hidden_layer_sizes=(3,))  \n",
    "#hidden_layer_sizesで層のユニット数を指定、中間層１つで3つのユニットから構成されていることを表している、(3,4)とすればユニット数4の中間層を右に追加\n",
    "cl.fit(train_X, train_Y)\n",
    "cl.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48624312156078037"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多クラス分類\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "cl = MLPClassifier(hidden_layer_sizes= (10,5))\n",
    "cl.fit(train_x, train_y)\n",
    "cl.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ディープラーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 計算能力の向上により、中間層を増やすことが可能となった\n",
    "* 勾配消失問題を解決するために発展した\n",
    "* 勾配消失問題：損失関数を最小化するために偏微分を繰り返して勾配を求めているものの、勾配が0のときに損失関数が最小となる問題\n",
    "* 勾配が0に近い場合、重みがほとんど更新されなくなる\n",
    "* 誤差逆伝播法の場合も、勾配消失によって学習が進まなくなる\n",
    "* $ Relu関数：f(I)=I,I≧0 ; f(I)=0,I＜0 $を活性化関数として学習を行う\n",
    "* 入力が1以上の時は勾配が1となり、1をいくらかけても勾配は小さくならないため、勾配消失を防ぐことができる\n",
    "* Batch Normalization、残差接続、重み共有、勾配クリッピング、ドロップアウトなどで、様々な問題を解決\n",
    "* 畳み込みニューラルネットワーク(CNN)やリカレントニューラルネットワーク(RNN)などが発展\n",
    "* 自然言語処理では、文という可変長のデータを取り扱うことから、RNNが広く使われている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 半教師あり学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 正解を一部のデータにだけ与えて学習する方法\n",
    "* 教師ありデータと教師なしデータの両方を与えて学習する\n",
    "* 教師ありデータを用意する際に、アノテーションが必要となり、手間が増える\n",
    "* アノテーション：コーパスに教師値の情報を追加すること\n",
    "* 教師なしデータとともに用いることで、精度の向上と手間の削減のバランスをとる\n",
    "\n",
    "* 教師ありデータを作成する手間を省きたい！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自己教示学習\n",
    "* a.教師ありデータを利用して分類器のモデルを学習→b.そのモデルを用いて教師なしデータを分類→c.推定されたラベルを正解と見なして再び学習を行ってモデルを作成\n",
    "* 分類器の精度が高いことを前提としている\n",
    "* 2つの分類器を用いる共学習、3つの分類器を用いるトライトレーニングなどのバリエーションがある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMアルゴリズム\n",
    "* 確率で割り振ってラベル付与\n",
    "* 期待値を求める処理のEステップと、最大化を行うMステップを交互に行うことで性能を向上させていく手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 自己教示学習の実践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = Make_dict('train.processed')\n",
    "train_X, train_Y = Make_sample_vectors('train.processed', features, labels)\n",
    "test_X, test_Y = Make_sample_vectors('test.processed', features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_X_arr = np.array(train_X)  #list型からnp.ndarray型へ変換\n",
    "train_Y_arr = np.array(train_Y)\n",
    "test_X_arr = np.array(test_X)\n",
    "test_Y_arr = np.array(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)  #乱数発生のオブジェクト\n",
    "random_unlabeled_points = rng.rand(train_Y_arr.shape[0]) < 0.3  \n",
    "#randモジュールでtrain_Y_arrの要素数分の乱数を発生させ、発生させた乱数が0.3未満であればTrue、そうでなければFalseを返すブール値の配列を作成\n",
    "train_Y_arr[random_unlabeled_points] = -1  #Trueなら-1に置換し、Falseならそのまま残す処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_Y_arr == -1)  #全2000件のうち、615件がラベルなしデータに分類された"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(train_Y_arr > -1)  #全2000件のうち、1385件がラベルありデータに分類された"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_arr_new = train_Y_arr[~random_unlabeled_points]\n",
    "train_X_arr_new = train_X_arr[~random_unlabeled_points]\n",
    "train_Y_arr_new.shape  #ラベル付きのデータ1385件を学習データとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 上記の学習データを用いてSVMを実行\n",
    "from sklearn.svm import SVC\n",
    "cl = SVC(probability=True, kernel='linear')  #自己教示学習を行う際に、推論の信頼性の予測値の確率が必要となるため、probability=Trueの指定が必要\n",
    "cl.fit(train_X_arr_new, train_Y_arr_new)\n",
    "cl.score(test_X_arr, test_Y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自己教示学習の実行\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "svc = SVC(probability=True, kernel='linear')\n",
    "self_training_model = SelfTrainingClassifier(svc)\n",
    "self_training_model.fit(train_X_arr, train_Y_arr)\n",
    "self_training_model.score(test_X_arr, test_Y_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ラベル伝播法\n",
    "* グラフベースの半教師あり学習\n",
    "* k近傍法カーネルを用いたラベル伝播法と重みづけを行った多数決によるk近傍法は類似している"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelPropagationモジュールとLabelSpreadingモジュールによるラベル伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "import numpy as np\n",
    "train_X_arr = np.array(train_X)\n",
    "train_Y_arr = np.array(train_Y)\n",
    "test_X_arr = np.array(test_X)\n",
    "test_Y_arr = np.array(test_Y)\n",
    "rng = np.random.RandomState(42)\n",
    "random_unlabeled_points = rng.rand(train_Y_arr.shape[0]) < 0.3\n",
    "labels = np.copy(train_Y_arr)  #train_y_arrのラベルを答え合わせに使うために複製\n",
    "labels[random_unlabeled_points] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=3)\n",
    "label_prop_model.fit(train_X_arr, labels)\n",
    "label_prop_model.score(train_X_arr, train_Y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c\n",
    "train_Y_arr2 = label_prop_model.predict(train_X_arr)  #ラベル伝播で推定したラベルを正解と見なす\n",
    "from sklearn.svm import LinearSVC\n",
    "cl = LinearSVC(C=1000)\n",
    "cl.fit(train_X_arr, train_Y_arr2)\n",
    "cl.score(test_X_arr, test_Y_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels > -1)  #教師ありデータの件数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルなしデータを利用せず、1385件の教師ありデータだけでSVMを実行\n",
    "train_Y_arr_new = train_Y_arr[~random_unlabeled_points]\n",
    "train_X_arr_new = train_X_arr[~random_unlabeled_points]\n",
    "cl=LinearSVC(C=1000)\n",
    "cl.fit(train_X_arr_new, train_Y_arr_new)\n",
    "cl.score(test_X_arr, test_Y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.717"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベル拡散法\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "label_prop_model =  LabelSpreading(kernel='knn', n_neighbors=3)\n",
    "label_prop_model.fit(train_X_arr, labels)\n",
    "label_prop_model.score(train_X_arr, train_Y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.642"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベル伝播したラベルの結果を正解と見なしてSVMで学習\n",
    "train_X_arr2=label_prop_model.predict(train_X_arr)\n",
    "cl=LinearSVC(C=1000)\n",
    "cl.fit(train_X_arr, train_Y_arr2)\n",
    "cl.score(test_X_arr, test_Y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープラーニングと共に使われる半教師あり学習の手法\n",
    "* word2vecの使用→文書のクラスが分からなくても学習できるため、アノテーションされていないコーパスから学習できる\n",
    "  * トランスダクティブ学習：半教師あり学習のもともと持っているラベルなしデータの予測だけを行い、新規データのラベルの予測をしない場合のこと\n",
    "* fine-tuning：ニューラルネットワークの重みパラメータの初期値として別のモデルのために学習した重みパラメータを設定することにより、モデルの性能を上げる手法\n",
    "* マルチタスク学習(?)：一部の重みを共有して学習する手法\n",
    "* 敵対的学習：生成器と識別器という二つのネットワークを使用する手法\n",
    "  * 生成器：できるだけ本物そっくりのサンプルを生成するモデル\n",
    "  * 識別器：生成器で作った偽物のサンプルと、与えられた本物のサンプルを見分ける機能を持つモデル\n",
    "  * 生成器と識別器を競わせるという点で、「敵対的」学習と呼ばれる\n",
    "  * 敵対的生成ネットワーク(GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 能動学習\n",
    "* 機械学習の最中に人手でラベル付けをして精度を上げる手法\n",
    "* 教師ありデータでモデルを作成した後、教師なしデータを適用してみて、モデルが判断に困った用例について人手でラベル付けを行い、その新たにラベル付けしたデータをもともとあった教師ありデータに追加して学習を行うことを繰り返す\n",
    "* SVMでは超平面から距離、ロジスティック回帰ではsoftmax関数やロジスティック関数の出力した確率からラベルを判断する\n",
    "* ラベル付けを行う手間がかかるが、AIとの共同作業でラベル付けを行うため、効率よくラベル付けができる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
